\section{Introduction}
\label{sec:introduction}

% What problem did you address in the project? Why is this problem interesting? What can we learn by solving the problem?

The day-to-day work of a doctor does not only include treating patients. Doctors must also constantly update their knowledge in their field. This in turn requires extensive reading of medical journals, where doctors wanting to update their knowledge spends about 4 hours a week on reading medical journals \cite{Garba2010ProliferationsBlessing}. Moreover, the volume of publications is rapidly increasing, making it impossible to keep up with the flow. Doctors must therefore be able to effectively pick out what journals are important for their own knowledge development and their current patients' needs. This often includes a quick glance at the title, introduction, and abstract to decide whether they should continue to read the journal, or rule it out \cite{Garba2010ProliferationsBlessing}. It is easy to conclude that limiting the search space would speed up this process, and allow doctors to spend more time on reading the journals that are actually important for their work. This is where medical NLP, and text classification, can play a role.

Text classification is a common task in Natural Language Processing (NLP) and is best described as the task of labeling or classifying a set of text into two or more specific classes. This can be done with a number of different techniques, and is most commonly done using supervised statistical machine learning (ML) techniques for classification, such as Naive Bayes, or Random Forest. These techniques requires labeled training data, typically consisting of examples of text paired with their corresponding class labels, in order to learn the patterns and characteristics of each class. But what if extensive labeled data is not available or hard to come by? In this case, one would typically turn to an unsupervised ML technique, such as K-means clustering. This project will however explore the use of Large Language Models (LLMs) and Generative AI, for the classification task.

Since the introduction of the transformer architecture, pioneered by Vaswani et al. \cite{Vaswani2017AttentionNeed}, the advancements of LLMs and Generative AI has surged. It is now easy to see that the potential for this technology is huge, and LLMs have shown to have great abilities in understanding, reasoning and generating text, as well as an ability to perform downstream NLP tasks. While this often includes fine-tuning the model to the specific task, this project aims to explore the capabilities of a general pre-trained model, not fine-tuned to the specific task, and seeks to find out the performance and effectiveness of such models on the text classification task in a medical context. Moreover, this will be compared and evaluated against more traditional supervised ML techniques for the same task.